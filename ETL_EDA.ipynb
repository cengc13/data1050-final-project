{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL_EDA\n",
    "This file records the process of acquiring raw data, traforming them, and loading them into a MongoDB. The data are store (almost) in their raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = np.array(['Washington', 'Wisconsin', 'Wyoming', 'Illinois', 'California',\n",
    "       'Arizona', 'Massachusetts', 'Texas', 'Nebraska', 'Utah', 'Oregon',\n",
    "       'Florida', 'New York', 'Rhode Island', 'Georgia', 'New Hampshire',\n",
    "       'North Carolina', 'New Jersey', 'Colorado', 'Maryland', 'Nevada',\n",
    "       'Tennessee', 'Hawaii', 'Indiana', 'Kentucky', 'Minnesota',\n",
    "       'Oklahoma', 'Pennsylvania', 'South Carolina',\n",
    "       'District of Columbia', 'Kansas', 'Missouri', 'Vermont',\n",
    "       'Virginia', 'Connecticut', 'Iowa', 'Louisiana', 'Ohio', 'Michigan',\n",
    "       'South Dakota', 'Arkansas', 'Delaware', 'Mississippi',\n",
    "       'New Mexico', 'North Dakota', 'Alaska', 'Maine', 'Alabama',\n",
    "       'Idaho', 'Montana', 'Puerto Rico', 'Virgin Islands', 'Guam',\n",
    "       'West Virginia', 'Northern Mariana Islands'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform and Load (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Raw Data from New York Times\n",
    "The [dataset](https://github.com/nytimes/covid-19-data) is a continuously updated txt file in csv format. It contains the covid case and death in the U.S. over time. It includes a cumulative series data at the national, state and county levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Raw Data to Documents/Dicts\n",
    "Using pandas, it is simple to parse a in-memory string. The first few lines of description need to be skipped. Datetime conversion is made and blank lines are dropped. Now the data can be easily converted to a list of dicts which is what we want for the MongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upsert MongoDB\n",
    "If we fetch the data frequently, there are lots of duplicate data entry between each run. The de-duplication happens at insertion. The MongoDB API to use is `collection.replace_one(filter=..., replacement=..., upsert=True)`. The statement matches a document in MongoDB with `filter`, replaces it with `replacement` if the document exists or inserts `replacement` into the database if `filter` matches nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'covid-us': \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv\",\n",
    "    'covid-us-state': \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\",\n",
    "    'covid-us-county': \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\",\n",
    "    'mask-use-by-county': \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/mask-use/mask-use-by-county.csv\"\n",
    "}\n",
    "\n",
    "filters = {\n",
    "    'covid-us': ['date'],\n",
    "    'covid-us-state': ['date', 'state'],\n",
    "    'covid-us-county': ['date', 'county'],\n",
    "    'mask-use-by-county': ['COUNTYFP']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_insert(level, url):\n",
    "    \"\"\"Request the data from url, and insert the data into\n",
    "    Mongodb database.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    level: str\n",
    "        geographical level for covid tracker\n",
    "    url: str\n",
    "        raw data link.\n",
    "    \"\"\"\n",
    "    ## Initialize the Mongodb database\n",
    "    client = pymongo.MongoClient()\n",
    "    \n",
    "    \n",
    "    ## Raw data from the websites\n",
    "    req = requests.get(url, timeout=0.5)\n",
    "    req.raise_for_status()\n",
    "    text = req.text\n",
    "    \n",
    "    ## Raw data to documents/dictionaries.\n",
    "    df = pd.read_csv(StringIO(text), delimiter=',')\n",
    "    df.columns = df.columns.str.strip()             # remove space in columns name\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    ## Upsert MongoDB\n",
    "    db = client.get_database(\"covid-us\")\n",
    "    collection = db.get_collection(level)\n",
    "    update_count = 0\n",
    "    if level == 'covid-us-county':\n",
    "        for state in all_states:\n",
    "            df_state = df[df['state'] == state]\n",
    "        for record in df_state.to_dict('records'):\n",
    "            filter_ = {_:record[_] for _ in filters[level]}\n",
    "            result = collection.replace_one(\n",
    "                filter=filter_,                             # locate the document if exists\n",
    "                replacement=record,                         # latest document\n",
    "                upsert=True)                                # update if exists, insert if not\n",
    "            if result.matched_count > 0:\n",
    "                update_count += 1\n",
    "    else:\n",
    "        for record in df.to_dict('records'):\n",
    "            filter_ = {_:record[_] for _ in filters[level]}\n",
    "            result = collection.replace_one(\n",
    "                filter=filter_,                             # locate the document if exists\n",
    "                replacement=record,                         # latest document\n",
    "                upsert=True)                                # update if exists, insert if not\n",
    "            if result.matched_count > 0:\n",
    "                update_count += 1\n",
    "    print(f\"{level.split('-')[-1]}:\",\n",
    "          f\"rows={df.shape[0]}, update={update_count}, \"\n",
    "          f\"insert={df.shape[0]-update_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scrape the data and insert the data into Mongoda database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us: rows=303, update=303, insert=0\n",
      "state: rows=14369, update=14369, insert=0\n",
      "county: rows=738157, update=256, insert=737901\n",
      "county: rows=3142, update=3142, insert=0\n",
      "CPU times: user 6.16 s, sys: 370 ms, total: 6.53 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for level, url in urls.items():\n",
    "    data_insert(level, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>10978295</td>\n",
       "      <td>245460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>11113482</td>\n",
       "      <td>246083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>11279747</td>\n",
       "      <td>246879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>11441484</td>\n",
       "      <td>248486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>11613875</td>\n",
       "      <td>250409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     cases  deaths\n",
       "298 2020-11-14  10978295  245460\n",
       "299 2020-11-15  11113482  246083\n",
       "300 2020-11-16  11279747  246879\n",
       "301 2020-11-17  11441484  248486\n",
       "302 2020-11-18  11613875  250409"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient()\n",
    "db = client.get_database(\"covid-us\")\n",
    "\n",
    "# national data \n",
    "collection = db.get_collection(\"covid-us\")\n",
    "\n",
    "# state-level data\n",
    "# collection = db.get_collection(\"covid-us-state\")\n",
    "\n",
    "# # county-level data\n",
    "# collection = db.get_collection(\"covid-us-county\")\n",
    "\n",
    "# # mask-use by county\n",
    "# collection = db.get_collection(\"mask-use-by-county\")\n",
    "\n",
    "data = list(collection.find())\n",
    "df = pd.DataFrame.from_records(data)    \n",
    "df.drop('_id', axis=1, inplace=True)\n",
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
